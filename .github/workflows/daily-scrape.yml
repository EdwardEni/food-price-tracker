name: Daily Scraper Run

on:
  schedule:
    # Runs every day at 2:00 AM UTC, adjust as needed
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  run-scraper-and-loader:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:latest
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: discombobulated
          POSTGRES_DB: food_price_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - name: Checkout repo (force ref)
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}
      - name: Assert workflow uses ETL path
        run: |
          if grep -R "src/loader/load_to_db.py" -n .github/workflows; then
            echo "Old path src/loader/load_to_db.py found in workflows — update to src/etl/load_to_db.py"
            exit 1
          else
            echo "No legacy loader path found — OK"
          fi
      - name: List files for debug
        run: ls -R
      - name: Echo loader script path from workflow YAML
        run: echo "Attempting to run: src/etl/load_to_db.py"
      - name: List 'src' and 'src/etl' folders
        run: |
          ls -l src
          ls -l src/etl
      - name: List workflow YAMLs for duplicate config
        run: |
          ls -l .github/workflows
          cat .github/workflows/daily-scrape.yml
      - name: Print branch and commit hash
        run: |
          git branch
          git rev-parse HEAD
      - name: List all Python files in repo
        run: find . -name "*.py"
      - name: Run ETL script via module import
        run: python -c "import src.etl.load_to_db"
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run scraper script (download CSV)
        run: python src/scraper/scrape.py
      - name: Check load_to_db.py existence
        run: |
          if [ -f src/etl/load_to_db.py ]; then
            echo "File exists"
          else
            echo "File NOT found"
            ls -l src/etl
            exit 1
          fi
      - name: Run data loader script (load to DB)
        env:
          DATABASE_URL: postgresql://postgres:discombobulated@localhost:5432/food_price_db
        run: python src/etl/load_to_db.py
      - name: Upload downloaded raw CSV
        uses: actions/upload-artifact@v4
        with:
          name: raw-wfp-food-prices-csv
          path: data/raw/wfpvam_foodprices.csv
