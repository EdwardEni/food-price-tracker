name: Daily Scraper Run

on:
  schedule:
    # Runs every day at 2:00 AM UTC, adjust as needed
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  run-scraper-and-loader:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:latest
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: discombobulated
          POSTGRES_DB: food_price_db
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      # Debug step: List all files in repo (recursive)
      - name: List files for debug 
        run: ls -R

      # Debug step: Echo the loader script path that workflow runs
      - name: Echo loader script path from workflow YAML
        run: echo "Attempting to run: src/etl/load_to_db.py"

      # Debug step: List contents of src and src/etl folders
      - name: List 'src' and 'src/etl' folders
        run: |
          ls -l src
          ls -l src/etl

      # Debug step: List workflow YAML files and display this file content for validation
      - name: List workflow YAMLs for duplicate config
        run: |
          ls -l .github/workflows
          cat .github/workflows/daily-scrape.yml

      # Debug step: Print the current branch and commit hash for confirmation
      - name: Print branch and commit hash
        run: |
          git branch
          git rev-parse HEAD

      # Debug step: List all Python files in the repository
      - name: List all Python files in repo
        run: find . -name "*.py"

      # Debug step: Try to import ETL script as module
      - name: Run ETL script via module import
        run: python -c "import src.etl.load_to_db"

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'      # Use a stable Python version for GitHub Actions

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run scraper script (download CSV)
        run: python src/scraper/scrape.py

      # Debug step: Check if load_to_db.py exists before running
      - name: Check load_to_db.py existence
        run: |
          if [ -f src/etl/load_to_db.py ]; then
            echo "File exists"
          else
            echo "File NOT found"
            ls -l src/etl
            exit 1
          fi

      # Ensure your load_to_db.py uses this database URL:
      # postgresql://postgres:discombobulated@localhost:5432/food_price_db

      - name: Run data loader script (load to DB)
        run: python src/etl/load_to_db.py

      - name: Upload downloaded raw CSV
        uses: actions/upload-artifact@v4
        with:
          name: raw-wfp-food-prices-csv
          path: data/raw/wfpvam_foodprices.csv
